[core]
# Specifies the home directory for Airflow; default is ~/airflow.
airflow_home = /usr/local/airflow

# Directory where the Airflow DAGs are stored.
dags_folder = /usr/local/airflow/dags

# Directory for storing Airflow log files. 
base_log_folder = /usr/local/airflow/logs

# Define executor type
executor = LocalExecutor

# Connection string for SQLAlchemy to connect to the Airflow metadata database.
sql_alchemy_conn = postgresql+psycopg2://airflow:airflow@postgres:5432/airflow

# Configures the connection pool size for SQLAlchemy.
sql_alchemy_pool_size = 5

# Path to the PID file for the daemon process.
pid = /usr/local/airflow/airflow-webserver.pid

# Default timezone for the Airflow UI.
default_timezone = utc

[webserver]
# Base URL for the Airflow web interface.
base_url = http://localhost:8080

# IP address on which the web server will listen.
web_server_host = 0.0.0.0

# Port number for the web server.
web_server_port = 8080

# Specifies the timeout duration (in seconds) for the Gunicorn web server worker.
web_server_worker_timeout = 120

# Defines the number of web server workers to refresh at once. 
worker_refresh_batch_size = 1

# Interval (in seconds) between worker refreshes.
worker_refresh_interval = 30

# Secret key used by Flask for session management and other security features.
secret_key = temporary_key

# Configures the number of threads for the Gunicorn web server.
workers = 4

[scheduler]
# Set the interval (in seconds) between heartbeats of task instances.
job_heartbeat_sec = 5
scheduler_heartbeat_sec = 5

# Interval (in seconds) between scheduler status checks.
scheduler_idle_sleep_time = 1

# Limits the number of concurrent task instances to be run by the scheduler.
max_threads = 2

# Limit the number of concurrent task instances allowed per DAG.
max_active_tasks_per_dag = 16
retry_delay = 300
min_file_process_interval = 0

# Directory where the scheduler searches for DAG definitions.
dags_folder = /usr/local/airflow/dags
dag_dir_list_interval = 300

# start the scheduler with the web server
run_scheduler = True

[logging]
# Directory for storing log files.
base_log_folder = /usr/local/airflow/logs
remote_logging = False
disable_local_log_storage = False

[metrics]
statsd_on = False
statsd_host = localhost
statsd_port = 8125
statsd_prefix = airflow

[ldap]
